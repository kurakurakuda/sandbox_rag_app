{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU openai pinecone-client datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, csv\n",
    "from openai import OpenAI\n",
    "from tqdm.autonotebook import tqdm\n",
    "import pinecone\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .envファイルを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# get API key for OpenAI and pinecone\n",
    "client = OpenAI(\n",
    "  api_key=os.getenv(\"OPENAI_API_KEY\"),  # this is also the default, it can be omitted\n",
    ")\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "print(client.api_key, pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csvに落とし込む\n",
    "csv_path = '../data/data.csv'\n",
    "raw_data = []\n",
    "\n",
    "with open(csv_path, mode='r', encoding='UTF-8', newline='') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        raw_data.append(row[0])\n",
    "\n",
    "# 読み取ったデータを表示\n",
    "for row in raw_data:\n",
    "    print(len(row), row)\n",
    "\n",
    "print(raw_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openaiで使用するmodelを宣言\n",
    "embed_model = \"EMBED_MODEL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1行に対して、Embeddingを作成してみる\n",
    "data = raw_data[0]\n",
    "res = client.embeddings.create(\n",
    "    input=[\n",
    "        data\n",
    "    ],\n",
    "    model=embed_model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成されたEmbeddingを見てみる(Skip可)\n",
    "print(len(res.data))\n",
    "print(len(res.data[0].embedding))\n",
    "print(res.data[0].embedding)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init pinecone\n",
    "index_name = \"sandbox\"\n",
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "pinecone.init(\n",
    "    api_key=pinecone_api_key,\n",
    "    environment=\"PINECONE_ENV\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sandbox']\n"
     ]
    }
   ],
   "source": [
    "# see pinecone which was initiated \n",
    "print(pinecone.list_indexes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create index in pinecone\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # if does not exist, create index\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=len(res.data[0].embedding),\n",
    "        metric='cosine'\n",
    "    )\n",
    "# connect to index\n",
    "index = pinecone.Index(index_name)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embeddings for all csv raws\n",
    "vectors = []\n",
    "# print(raw_data)\n",
    "res = client.embeddings.create(\n",
    "    input=raw_data,\n",
    "    model=embed_model\n",
    ")\n",
    "print(len(res.data))\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upserts the vectors created by openai embeddings to pinecone\n",
    "for i, data in enumerate(raw_data):\n",
    "    v = res.data[i].embedding\n",
    "    print(i, v, data)\n",
    "    vectors.append(\n",
    "        {\n",
    "            'id': str(i), \n",
    "            'values': v,\n",
    "            'metadata': {\n",
    "                'text': data\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n",
    "index.upsert(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the query, embeddings it and query to pinecone\n",
    "query = (\n",
    "    \"QUERY_TEXT\"\n",
    ")\n",
    "res = client.embeddings.create(\n",
    "    input=[query],\n",
    "    model=embed_model\n",
    ")\n",
    "\n",
    "# retrieve from Pinecone\n",
    "xq = res.data[0].embedding\n",
    "\n",
    "# get relevant contexts (including the questions)\n",
    "res = index.query(xq, top_k=2, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the response from pinecone\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the core of 検索拡張生成 (RAG: Retrieval Augmented Generation)\n",
    "# query the openai with external knowledge fetched by the query result from pinecone\n",
    "model = 'GPT_MODEL'\n",
    "context = \"\\n\\n---\\n\\n\".join([item['metadata']['text'] for item in res['matches']])\n",
    "# context = res['matches'][0]['metadata']['text']\n",
    "question = \"QUESTION_TO_RAG_APP\"\n",
    "ans = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "                {\"role\": \"system\", \"content\": \"\"\"あなたは、精確な野球の記者です。下記のコンテキストをもとに、質問に回答してください。\n",
    "                    もしコンテキスト内に回答がなければ、次のように回答してください。 \\\"私が知っている限りにおいて、回答することはできません。\\\"\\n\\n \n",
    "                    では、深呼吸をして、この問題に一歩一歩取り組んでいきましょう。\\n\\n\"\"\"},\n",
    "                {\"role\": \"user\", \"content\": \"コンテキスト: \" + context + \"\\n\\n---\\n\\n質問: \" + question + \"\\n回答:\"}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            # max_tokens=1800,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=None,\n",
    ")\n",
    "print(ans)\n",
    "print(ans.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the record from pinecone\n",
    "index.fetch(['9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all records in pinecone\n",
    "id_ttl = 9\n",
    "id_list = [str(i) for i in range(id_ttl)]\n",
    "print(id_list)\n",
    "index.delete(ids=id_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
